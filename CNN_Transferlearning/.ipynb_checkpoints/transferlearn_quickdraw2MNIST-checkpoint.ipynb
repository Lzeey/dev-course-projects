{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Experiment\n",
    "\n",
    "In last week's exercise, we trained a quickdraw classifier (200 class, 10K examples - 78% acc).\n",
    "Would it be possible to directly use the outputs of the network to classify MNIST without further training?\n",
    "\n",
    "Strategy:\n",
    "1. Pump MNIST through the network\n",
    "2. Take the logits layer\n",
    "3. Classify using XGB/SVM\n",
    "4. Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#from sutils import *\n",
    "import os, json\n",
    "import pickle\n",
    "#from os import walk\n",
    "#from glob import glob\n",
    "\n",
    "#from keras.applications import inception_v3\n",
    "#from keras.applications import vgg16\n",
    "import keras\n",
    "from keras.preprocessing import image \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv01_01 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "Conv01_02 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "Conv01_03 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "MaxPool01_layer (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv02_01 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv02_02 (Conv2D)           (None, 8, 8, 192)         221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "Conv02_03 (Conv2D)           (None, 6, 6, 256)         442624    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "MaxPool02_layer (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "Dropout02_layer (Dropout)    (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "Flatten_layer (Flatten)      (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "Dense01_layer (Dense)        (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "Dropout03_layer (Dropout)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "logits_layer (Dense)         (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "Sofftmax_layer (Activation)  (None, 200)               0         \n",
      "=================================================================\n",
      "Total params: 2,053,544\n",
      "Trainable params: 2,051,112\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load previous model\n",
    "\n",
    "model_name = \"quickdraw_200cls_10k_CNN.h5\"\n",
    "\n",
    "yaml_str = pickle.load(open('yaml' + model_name + '.pkl', 'rb'))\n",
    "base_model = keras.models.model_from_yaml(yaml_str)\n",
    "base_model.load_weights('weights' + model_name)\n",
    "\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits_out = base_model.get_layer('batch_normalization_7')\n",
    "model = Model(inputs=base_model.input, outputs=logits_out.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import struct\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "path = './data/fashion/'\n",
    "\n",
    "x_train, y_train = load_mnist(path, kind='train')\n",
    "x_test, y_test = load_mnist(path, kind='t10k')\n",
    "\n",
    "x_train = x_train.reshape((-1, 28, 28))\n",
    "x_test = x_test.reshape((-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n",
      "[[[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.01568628]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.24313726]\n",
      "  [ 0.23921569]\n",
      "  [ 0.08235294]\n",
      "  [ 0.11372549]\n",
      "  [ 0.09019608]\n",
      "  [ 0.2       ]\n",
      "  [ 0.53333336]\n",
      "  [ 0.23921569]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.34509805]\n",
      "  [ 0.78823531]\n",
      "  [ 0.89411765]\n",
      "  [ 0.88235295]\n",
      "  [ 1.        ]\n",
      "  [ 0.4509804 ]\n",
      "  [ 0.24313726]\n",
      "  [ 0.53725493]\n",
      "  [ 1.        ]\n",
      "  [ 0.92156863]\n",
      "  [ 0.87058824]\n",
      "  [ 1.        ]\n",
      "  [ 0.52941179]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.18431373]\n",
      "  [ 0.98823529]\n",
      "  [ 0.91764706]\n",
      "  [ 0.93333334]\n",
      "  [ 0.87843138]\n",
      "  [ 0.84313726]\n",
      "  [ 0.84313726]\n",
      "  [ 0.89803922]\n",
      "  [ 0.42352942]\n",
      "  [ 0.70588237]\n",
      "  [ 0.81176472]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.87843138]\n",
      "  [ 0.90588236]\n",
      "  [ 0.97647059]\n",
      "  [ 0.99607843]\n",
      "  [ 0.17647059]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.87058824]\n",
      "  [ 0.82352942]\n",
      "  [ 0.83529413]\n",
      "  [ 0.87843138]\n",
      "  [ 0.88235295]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.86274511]\n",
      "  [ 0.99607843]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.85882354]\n",
      "  [ 0.86666667]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.87450981]\n",
      "  [ 0.86666667]\n",
      "  [ 0.94117647]\n",
      "  [ 0.99607843]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.50196081]\n",
      "  [ 0.92941177]\n",
      "  [ 0.81176472]\n",
      "  [ 0.87843138]\n",
      "  [ 0.87843138]\n",
      "  [ 0.81176472]\n",
      "  [ 0.84705883]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81568629]\n",
      "  [ 0.82745099]\n",
      "  [ 0.86666667]\n",
      "  [ 0.81568629]\n",
      "  [ 0.85882354]\n",
      "  [ 0.83529413]\n",
      "  [ 0.88627452]\n",
      "  [ 0.82745099]\n",
      "  [ 0.92941177]\n",
      "  [ 0.58823532]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.00784314]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.92941177]\n",
      "  [ 0.87058824]\n",
      "  [ 0.84313726]\n",
      "  [ 0.81176472]\n",
      "  [ 0.82352942]\n",
      "  [ 0.83137256]\n",
      "  [ 0.83529413]\n",
      "  [ 0.80784315]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.83529413]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.83529413]\n",
      "  [ 0.82352942]\n",
      "  [ 0.84313726]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.80784315]\n",
      "  [ 0.78039217]\n",
      "  [ 0.85490197]\n",
      "  [ 1.        ]\n",
      "  [ 0.05098039]\n",
      "  [ 0.        ]\n",
      "  [ 0.00784314]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.01568628]\n",
      "  [ 0.        ]\n",
      "  [ 0.33333334]\n",
      "  [ 0.89411765]\n",
      "  [ 0.82352942]\n",
      "  [ 0.85490197]\n",
      "  [ 0.78431374]\n",
      "  [ 0.82745099]\n",
      "  [ 0.81568629]\n",
      "  [ 0.79607844]\n",
      "  [ 0.84313726]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81960785]\n",
      "  [ 0.81960785]\n",
      "  [ 0.82352942]\n",
      "  [ 0.83529413]\n",
      "  [ 0.82745099]\n",
      "  [ 0.82352942]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.80784315]\n",
      "  [ 0.83529413]\n",
      "  [ 0.90588236]\n",
      "  [ 0.68627453]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.87843138]\n",
      "  [ 0.84313726]\n",
      "  [ 0.80784315]\n",
      "  [ 0.80392158]\n",
      "  [ 0.80000001]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.90196079]\n",
      "  [ 0.87058824]\n",
      "  [ 0.84313726]\n",
      "  [ 0.87843138]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.89411765]\n",
      "  [ 0.90980393]\n",
      "  [ 0.89411765]\n",
      "  [ 0.87843138]\n",
      "  [ 0.81176472]\n",
      "  [ 0.83137256]\n",
      "  [ 0.84313726]\n",
      "  [ 0.83529413]\n",
      "  [ 0.89803922]\n",
      "  [ 0.12156863]\n",
      "  [ 0.        ]\n",
      "  [ 0.01568628]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.08235294]\n",
      "  [ 0.88235295]\n",
      "  [ 0.83137256]\n",
      "  [ 0.83137256]\n",
      "  [ 0.79607844]\n",
      "  [ 0.82745099]\n",
      "  [ 0.88235295]\n",
      "  [ 0.75686276]\n",
      "  [ 0.54509807]\n",
      "  [ 0.53333336]\n",
      "  [ 0.7647059 ]\n",
      "  [ 0.57647061]\n",
      "  [ 0.61176473]\n",
      "  [ 0.54509807]\n",
      "  [ 0.50196081]\n",
      "  [ 0.63529414]\n",
      "  [ 0.77254903]\n",
      "  [ 0.87450981]\n",
      "  [ 0.81176472]\n",
      "  [ 0.86274511]\n",
      "  [ 0.83529413]\n",
      "  [ 0.90980393]\n",
      "  [ 0.69411767]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.48235294]\n",
      "  [ 0.88627452]\n",
      "  [ 0.81176472]\n",
      "  [ 0.82745099]\n",
      "  [ 0.81960785]\n",
      "  [ 0.80392158]\n",
      "  [ 0.89411765]\n",
      "  [ 0.61960787]\n",
      "  [ 0.35294119]\n",
      "  [ 0.40392157]\n",
      "  [ 0.72941178]\n",
      "  [ 0.5411765 ]\n",
      "  [ 0.39215687]\n",
      "  [ 0.47450981]\n",
      "  [ 0.57647061]\n",
      "  [ 0.61960787]\n",
      "  [ 0.71764708]\n",
      "  [ 0.88627452]\n",
      "  [ 0.81568629]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.81960785]\n",
      "  [ 0.84705883]\n",
      "  [ 1.        ]\n",
      "  [ 0.05098039]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.88627452]\n",
      "  [ 0.85882354]\n",
      "  [ 0.79215688]\n",
      "  [ 0.81568629]\n",
      "  [ 0.80784315]\n",
      "  [ 0.80392158]\n",
      "  [ 0.84705883]\n",
      "  [ 0.72156864]\n",
      "  [ 0.61176473]\n",
      "  [ 0.58823532]\n",
      "  [ 0.75686276]\n",
      "  [ 0.66666669]\n",
      "  [ 0.64313728]\n",
      "  [ 0.65882355]\n",
      "  [ 0.73725492]\n",
      "  [ 0.72941178]\n",
      "  [ 0.78431374]\n",
      "  [ 0.85882354]\n",
      "  [ 0.84705883]\n",
      "  [ 0.83529413]\n",
      "  [ 0.83529413]\n",
      "  [ 0.82745099]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.58039218]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.17647059]\n",
      "  [ 0.89019608]\n",
      "  [ 0.80000001]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.82745099]\n",
      "  [ 0.85490197]\n",
      "  [ 0.87058824]\n",
      "  [ 0.86666667]\n",
      "  [ 0.90196079]\n",
      "  [ 0.89803922]\n",
      "  [ 0.86666667]\n",
      "  [ 0.83529413]\n",
      "  [ 0.87843138]\n",
      "  [ 0.9137255 ]\n",
      "  [ 0.88627452]\n",
      "  [ 0.86274511]\n",
      "  [ 0.85882354]\n",
      "  [ 0.86666667]\n",
      "  [ 0.87843138]\n",
      "  [ 0.87450981]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.82352942]\n",
      "  [ 0.85490197]\n",
      "  [ 0.83529413]\n",
      "  [ 0.99607843]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.6156863 ]\n",
      "  [ 0.88627452]\n",
      "  [ 0.79607844]\n",
      "  [ 0.81176472]\n",
      "  [ 0.82745099]\n",
      "  [ 0.81960785]\n",
      "  [ 0.84313726]\n",
      "  [ 0.80392158]\n",
      "  [ 0.7764706 ]\n",
      "  [ 0.81176472]\n",
      "  [ 0.81568629]\n",
      "  [ 0.78823531]\n",
      "  [ 0.78823531]\n",
      "  [ 0.77254903]\n",
      "  [ 0.79607844]\n",
      "  [ 0.80392158]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81176472]\n",
      "  [ 0.83529413]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.83529413]\n",
      "  [ 0.81568629]\n",
      "  [ 0.91764706]\n",
      "  [ 0.41960785]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.92156863]\n",
      "  [ 0.83529413]\n",
      "  [ 0.80000001]\n",
      "  [ 0.82745099]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81960785]\n",
      "  [ 0.83529413]\n",
      "  [ 0.79215688]\n",
      "  [ 0.77254903]\n",
      "  [ 0.80000001]\n",
      "  [ 0.84313726]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.83529413]\n",
      "  [ 0.83137256]\n",
      "  [ 0.82352942]\n",
      "  [ 0.80784315]\n",
      "  [ 0.83137256]\n",
      "  [ 0.79607844]\n",
      "  [ 0.82745099]\n",
      "  [ 0.85490197]\n",
      "  [ 0.84313726]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81960785]\n",
      "  [ 0.87058824]\n",
      "  [ 0.90196079]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.20392157]\n",
      "  [ 1.        ]\n",
      "  [ 0.81176472]\n",
      "  [ 0.78431374]\n",
      "  [ 0.81568629]\n",
      "  [ 0.83529413]\n",
      "  [ 0.82352942]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81176472]\n",
      "  [ 0.79215688]\n",
      "  [ 0.78823531]\n",
      "  [ 0.81960785]\n",
      "  [ 0.84705883]\n",
      "  [ 0.84705883]\n",
      "  [ 0.84705883]\n",
      "  [ 0.84705883]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.83137256]\n",
      "  [ 0.80392158]\n",
      "  [ 0.84313726]\n",
      "  [ 0.78823531]\n",
      "  [ 0.89411765]\n",
      "  [ 0.81568629]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.83137256]\n",
      "  [ 0.85490197]\n",
      "  [ 0.09803922]]\n",
      "\n",
      " [[ 0.4627451 ]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.78823531]\n",
      "  [ 0.80784315]\n",
      "  [ 0.81568629]\n",
      "  [ 0.83529413]\n",
      "  [ 0.81568629]\n",
      "  [ 0.80392158]\n",
      "  [ 0.80784315]\n",
      "  [ 0.82352942]\n",
      "  [ 0.82745099]\n",
      "  [ 0.79215688]\n",
      "  [ 0.78039217]\n",
      "  [ 0.81176472]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81960785]\n",
      "  [ 0.82352942]\n",
      "  [ 0.81176472]\n",
      "  [ 0.82352942]\n",
      "  [ 0.82352942]\n",
      "  [ 0.96078432]\n",
      "  [ 0.54509807]\n",
      "  [ 0.46666667]\n",
      "  [ 1.        ]\n",
      "  [ 0.79215688]\n",
      "  [ 0.79607844]\n",
      "  [ 0.9254902 ]\n",
      "  [ 0.44705883]]\n",
      "\n",
      " [[ 0.67058825]\n",
      "  [ 0.93333334]\n",
      "  [ 0.83137256]\n",
      "  [ 0.79607844]\n",
      "  [ 0.86274511]\n",
      "  [ 0.84705883]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.81960785]\n",
      "  [ 0.81176472]\n",
      "  [ 0.80392158]\n",
      "  [ 0.82352942]\n",
      "  [ 0.82745099]\n",
      "  [ 0.80784315]\n",
      "  [ 0.80000001]\n",
      "  [ 0.80784315]\n",
      "  [ 0.81960785]\n",
      "  [ 0.82745099]\n",
      "  [ 0.84313726]\n",
      "  [ 0.82352942]\n",
      "  [ 0.80784315]\n",
      "  [ 0.86666667]\n",
      "  [ 0.94901961]\n",
      "  [ 0.        ]\n",
      "  [ 0.87843138]\n",
      "  [ 0.91764706]\n",
      "  [ 0.90196079]\n",
      "  [ 0.70980394]\n",
      "  [ 0.10196079]]\n",
      "\n",
      " [[ 0.15294118]\n",
      "  [ 0.56862748]\n",
      "  [ 0.78823531]\n",
      "  [ 1.        ]\n",
      "  [ 0.6156863 ]\n",
      "  [ 0.4509804 ]\n",
      "  [ 0.98039216]\n",
      "  [ 0.78431374]\n",
      "  [ 0.81176472]\n",
      "  [ 0.80784315]\n",
      "  [ 0.81176472]\n",
      "  [ 0.83529413]\n",
      "  [ 0.84705883]\n",
      "  [ 0.80784315]\n",
      "  [ 0.80392158]\n",
      "  [ 0.80784315]\n",
      "  [ 0.81176472]\n",
      "  [ 0.80784315]\n",
      "  [ 0.84313726]\n",
      "  [ 0.81176472]\n",
      "  [ 0.86666667]\n",
      "  [ 0.93333334]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.73725492]\n",
      "  [ 0.33333334]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.12156863]\n",
      "  [ 0.        ]\n",
      "  [ 0.50588238]\n",
      "  [ 0.99215686]\n",
      "  [ 0.74509805]\n",
      "  [ 0.81176472]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81568629]\n",
      "  [ 0.81960785]\n",
      "  [ 0.82745099]\n",
      "  [ 0.82745099]\n",
      "  [ 0.81960785]\n",
      "  [ 0.81960785]\n",
      "  [ 0.81960785]\n",
      "  [ 0.83137256]\n",
      "  [ 0.78823531]\n",
      "  [ 0.88627452]\n",
      "  [ 0.64705884]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.00784314]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.34901962]\n",
      "  [ 0.99607843]\n",
      "  [ 0.78039217]\n",
      "  [ 0.78039217]\n",
      "  [ 0.75294119]\n",
      "  [ 0.76862746]\n",
      "  [ 0.7764706 ]\n",
      "  [ 0.78039217]\n",
      "  [ 0.78823531]\n",
      "  [ 0.79215688]\n",
      "  [ 0.79607844]\n",
      "  [ 0.80000001]\n",
      "  [ 0.79607844]\n",
      "  [ 0.79607844]\n",
      "  [ 0.78431374]\n",
      "  [ 0.87058824]\n",
      "  [ 0.60784316]\n",
      "  [ 0.        ]\n",
      "  [ 0.01176471]\n",
      "  [ 0.01176471]\n",
      "  [ 0.01176471]\n",
      "  [ 0.00784314]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.01960784]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 1.        ]\n",
      "  [ 0.85490197]\n",
      "  [ 0.88627452]\n",
      "  [ 0.90980393]\n",
      "  [ 0.89411765]\n",
      "  [ 0.87843138]\n",
      "  [ 0.87058824]\n",
      "  [ 0.86274511]\n",
      "  [ 0.85882354]\n",
      "  [ 0.85882354]\n",
      "  [ 0.8509804 ]\n",
      "  [ 0.86666667]\n",
      "  [ 0.86274511]\n",
      "  [ 0.83137256]\n",
      "  [ 0.9254902 ]\n",
      "  [ 0.37254903]\n",
      "  [ 0.        ]\n",
      "  [ 0.00784314]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.60784316]\n",
      "  [ 0.76078433]\n",
      "  [ 0.65882355]\n",
      "  [ 0.66666669]\n",
      "  [ 0.67058825]\n",
      "  [ 0.67843139]\n",
      "  [ 0.67843139]\n",
      "  [ 0.7019608 ]\n",
      "  [ 0.69411767]\n",
      "  [ 0.68627453]\n",
      "  [ 0.67450982]\n",
      "  [ 0.67058825]\n",
      "  [ 0.65490198]\n",
      "  [ 0.63137257]\n",
      "  [ 0.70588237]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST (can replace with fashion MNIST also)\n",
    "#from keras.datasets import fashion_mnist as mnist\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255\n",
    "x_test = x_test.astype(np.float32) / 255\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_embed = model.predict(x_train)\n",
    "x_test_embed = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 512) (10000, 512)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_embed.shape, x_test_embed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This step is important. Scale the embeddings!\n",
    "scaler = StandardScaler()\n",
    "x_train_embed = scaler.fit_transform(x_train_embed)\n",
    "x_test_embed = scaler.transform(x_test_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(dual=False)\n",
    "clf.fit(x_train_embed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85229999999999995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing time\n",
    "y_test_pred = clf.predict(x_test_embed)\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "An okay score.... recall the fully connected network in week 01 scored 85% acc (though it trained on the dataset directly). Perhaps more accuracy can be gained with hyperparameter tuning (which kinda defeats the purpose of transfer-learning though).\n",
    "\n",
    "For sanity check, look at how well the raw svm performs without embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(dual=False)\n",
    "clf.fit(x_train.reshape((-1, 784)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85019999999999996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = clf.predict(x_test.reshape((-1, 784)))\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the linearSVM on raw pixels can do even better than our transfer-learned network. Perhaps the output classes from the 200 class quickdraw dataset is underpowered for more task (usually only works with more powerful datasets like imagenet, it seems?)\n",
    "\n",
    "Thought: How about a powerful classifier like xgb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "function 'XGDMatrixCreateFromMat_omp' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-85d80fddce3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Zeyi\\Anaconda2\\envs\\python35\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    262\u001b[0m                                    missing=self.missing, nthread=self.n_jobs)\n\u001b[1;32m    263\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mtrainDmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Zeyi\\Anaconda2\\envs\\python35\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Zeyi\\Anaconda2\\envs\\python35\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 ctypes.byref(self.handle)))\n\u001b[1;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             _check_call(_LIB.XGDMatrixCreateFromMat_omp(\n\u001b[0m\u001b[1;32m    358\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Zeyi\\Anaconda2\\envs\\python35\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Zeyi\\Anaconda2\\envs\\python35\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FuncPtr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: function 'XGDMatrixCreateFromMat_omp' not found"
     ]
    }
   ],
   "source": [
    "clf = xgboost.XGBRegressor()\n",
    "clf.fit(x_train.reshape((-1, 784)), y_train)\n",
    "y_test_pred = clf.predict(x_test.reshape((-1, 784)))\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "We were performing transfer learning on the full dataset. Can we look at transfer learning performance on a small subset of the data instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 30 samples\n",
      "Accuracy (transfer): 0.486600\n",
      "Accuracy (raw): 0.609600\n",
      "Training on 100 samples\n",
      "Accuracy (transfer): 0.593100\n",
      "Accuracy (raw): 0.678500\n",
      "Training on 300 samples\n",
      "Accuracy (transfer): 0.697000\n",
      "Accuracy (raw): 0.767500\n",
      "Training on 1000 samples\n",
      "Accuracy (transfer): 0.728100\n",
      "Accuracy (raw): 0.800000\n",
      "Training on 3000 samples\n",
      "Accuracy (transfer): 0.778500\n",
      "Accuracy (raw): 0.817100\n",
      "Training on 10000 samples\n",
      "Accuracy (transfer): 0.823000\n",
      "Accuracy (raw): 0.828500\n"
     ]
    }
   ],
   "source": [
    "train_sizes = np.array([3, 10, 30, 100, 300, 1000]) * 10 #10 classes\n",
    "\n",
    "acc_transfer_hist = []\n",
    "acc_raw_hist = []\n",
    "\n",
    "def train_and_predict(x_train, y_train, x_test, y_test):\n",
    "    parameters = {'C':[0.2, 1, 5, 10]}\n",
    "    #clf = svm.LinearSVC(dual=False)\n",
    "    clf = GridSearchCV(svm.LinearSVC(dual=False), parameters, scoring='accuracy', n_jobs=4)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    return acc    \n",
    "    \n",
    "for idx, samples in enumerate(train_sizes):\n",
    "    print(\"Training on %d samples\" % samples)\n",
    "    x_train_sub, _, x_train_raw, _, y_train_sub, _ = train_test_split(x_train_embed, x_train.reshape((-1, 784)), y_train, train_size=samples, stratify=y_train)\n",
    "    transfer_acc = train_and_predict(x_train_sub, y_train_sub, x_test_embed, y_test)\n",
    "    acc_transfer_hist.append(transfer_acc)\n",
    "    \n",
    "    #x_train_sub, _, y_train_sub, _ = train_test_split(x_train.reshape((-1, 784)), y_train, train_size=samples, stratify=y_train)\n",
    "    raw_acc = train_and_predict(x_train_raw, y_train_sub, x_test.reshape((-1, 784)), y_test)\n",
    "    acc_raw_hist.append(raw_acc)\n",
    "    print(\"Accuracy (transfer): %f\" % acc_transfer_hist[idx])\n",
    "    print(\"Accuracy (raw): %f\" % acc_raw_hist[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEaCAYAAADpMdsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLGDE0wYJ89wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28702dba1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train():\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(train_sizes, acc_transfer_hist)\n",
    "    plt.plot(train_sizes, acc_raw_hist)\n",
    "    plt.title('Test accuracy vs number of samples (total)')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel('Num. examples')\n",
    "    plt.legend(['transfer learned', 'raw'], loc='lower right')\n",
    "    \n",
    "plot_train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Explain why this is the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
